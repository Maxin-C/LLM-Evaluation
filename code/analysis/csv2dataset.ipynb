{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_q(col_name):\n",
    "    pattern = r\"!\\[(\\d+)\\.png\\].*?\\{auto，auto\\}:(.*)\"\n",
    "    match = re.search(pattern, col_name)\n",
    "\n",
    "    if match:\n",
    "        number = int(match.group(1))\n",
    "        if number == 200:\n",
    "            number = 0\n",
    "        question = match.group(2).strip()\n",
    "        return number, question\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2num(result):\n",
    "    order = [\n",
    "        \"是否认同模型回答能够容易地被非医学背景的读者理解并应用？\",\n",
    "        '是否认同模型的推理过程与临床推理逻辑保持一致？',\n",
    "        '是否认同模型回答考虑到了患者特定的病理特征？',\n",
    "        '是否认同模型回答存在误导性风险建议？',\n",
    "        '是否认同模型回答考虑到了患者的情感需求？'\n",
    "    ]\n",
    "    num = []\n",
    "    for key in order:\n",
    "        if key == \"是否认同模型回答存在误导性风险建议？\":\n",
    "            num.append(4-result[key])\n",
    "        else:\n",
    "            num.append(result[key])\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_A(df):\n",
    "    dataset = []\n",
    "    for _, row in df.iterrows():\n",
    "        # if row['地理位置省'] != \"辽宁省\":\n",
    "        if True:\n",
    "            evaluator = []\n",
    "            cur_index = -1\n",
    "            for col_name, value in row.items():\n",
    "                index, q = get_index_q(col_name)\n",
    "                if index != None:\n",
    "                    if index != cur_index:\n",
    "                        if cur_index != -1:\n",
    "                            data['num'] = result2num(data['result'])\n",
    "                            evaluator.append(data)\n",
    "                        data = {\n",
    "                            \"id\": index,\n",
    "                            \"result\" : {\n",
    "                                q: value\n",
    "                            },\n",
    "                            \"num\": [],\n",
    "                            \"form\": \"A\",\n",
    "                            \"model\": \"GPT\" if index>=100 else \"DS\"\n",
    "                        }\n",
    "                        cur_index = index\n",
    "                    else:\n",
    "                        data[\"result\"][q] = value\n",
    "            data['num'] = result2num(data['result'])\n",
    "            evaluator.append(data)\n",
    "            dataset.append(evaluator)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_B(df):\n",
    "    dataset = []\n",
    "    for _, row in df.iterrows():\n",
    "        evaluator = []\n",
    "        cur_index = -1\n",
    "        for col_name, value in row.items():\n",
    "            index, q = get_index_q(col_name)\n",
    "            if index != None:\n",
    "                if index != cur_index:\n",
    "                    if cur_index != -1:\n",
    "                        data['num'] = result2num(data['result'])\n",
    "                        evaluator.append(data)\n",
    "                    data = {\n",
    "                        \"id\": index,\n",
    "                        \"result\" : {\n",
    "                            q: value\n",
    "                        },\n",
    "                        \"num\": [],\n",
    "                        \"form\": \"B\",\n",
    "                        \"model\": \"GPT\" if index>=100 else \"DS\"\n",
    "                    }\n",
    "                    cur_index = index\n",
    "                else:\n",
    "                    data[\"result\"][q] = value\n",
    "        data['num'] = result2num(data['result'])\n",
    "        evaluator.append(data)\n",
    "        dataset.append(evaluator)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_B_reverse(df):\n",
    "    dataset = []\n",
    "    for _, row in df.iterrows():\n",
    "        evaluator = []\n",
    "        cur_index = -1\n",
    "        for col_name, value in row.items():\n",
    "            index, q = get_index_q(col_name)\n",
    "            if index != None:\n",
    "                if index != cur_index:\n",
    "                    if cur_index != -1:\n",
    "                        data['num'] = result2num(data['result'])\n",
    "                        evaluator.append(data)\n",
    "                    data = {\n",
    "                        \"id\": index,\n",
    "                        \"result\" : {\n",
    "                            q: value\n",
    "                        },\n",
    "                        \"num\": [],\n",
    "                        \"form\": \"B\",\n",
    "                        \"model\": \"DS\" if index>=100 else \"GPT\"\n",
    "                    }\n",
    "                    cur_index = index\n",
    "                else:\n",
    "                    data[\"result\"][q] = value\n",
    "        data['num'] = result2num(data['result'])\n",
    "        evaluator.append(data)\n",
    "        dataset.append(evaluator)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_A = [[],[]]\n",
    "dataset_B = [[],[]]\n",
    "for file in os.listdir(\"../../survey_result/csv\"):\n",
    "    if file.startswith(\"A\") and file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(\"../../survey_result/csv\", file))\n",
    "        dataset = process_A(df)\n",
    "        dataset_A[0].extend(dataset[0])\n",
    "        dataset_A[1].extend(dataset[1])\n",
    "    if file.startswith(\"B\") and file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(\"../../survey_result/csv\", file))\n",
    "        if file == \"B.csv\":\n",
    "            dataset_B[0] = process_B(df)[0]\n",
    "        else:\n",
    "            dataset_B[1].extend(process_B_reverse(df)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dataset_A, open(\"../../survey_result/dataset_A.json\", 'w'), ensure_ascii=False)\n",
    "json.dump(dataset_B, open(\"../../survey_result/dataset_B.json\", 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_A[0]+dataset_B[0]+dataset_A[1]+dataset_B[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dataset, open(\"../../survey_result/dataset.json\", 'w'), ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
